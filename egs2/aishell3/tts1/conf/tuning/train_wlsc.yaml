# This configuration is for ESPnet2 to train Conformer-based
# FastSpeech2 with GST + X-vector. It requires 4 GPU with 32 GB
# memory and it takes ~3 days to finish the training on V100.

# Compared to the original FastSpeech2 paper, we use token
# averaged pitch and energy as the same as FastPitch.
# And we do not use quantized pitch and energy.

# For FastSpeech2, we need to extract pitch and energy.
# Therefore, we assume that feats_type=raw in using this
# configuration. Please be careful.

##########################################################
#                  TTS MODEL SETTING                     #
##########################################################
tts: wlsc      # model architecture
tts_conf:             # keyword arguments for the selected model
    spk_embed_dim: 24
    phone_embed_dim: 128
    #word_seq_embed_dim: 72
    # word_seq_proj_dim: 72
    # style_token_dim: 72
    # word_seq_encoder_dropout: 0.0
    encoder_adim: 128
    encoder_linear_units: 128
    encoder_aheads: 2
    encoder_numblocks: 1
    encoder_dropout_rate: 0.0
    encoder_positional_dropout_rate: 0.1
    encoder_attention_dropout_rate: 0.1
    # encoder_conv_kernel_size: 5
    # encoder_positionwise_layer_type: "linear"
    # encoder_use_cnn_module: true
    # style_encoder_aheads: 2
    decoder_adim: 128
    decoder_aheads: 4
    decoder_numblocks: 3
    decoder_positionwise_layer_type: "conv1d-linear"
    decoder_positionwise_conv_kernel_size: 7
    decoder_use_cnn_module: false
    decoder_dropout_rate: 0.1
    decoder_positional_dropout_rate: 0.1
    decoder_attention_dropout_rate: 0.1
    decoder_cnn_module_kernel: 21
    decoder_linear_units: 1024
# extra module for additional inputs
#pitch_extract: dio           # pitch extractor type
#pitch_normalize: global_mvn  # normalizer for the pitch feature
#energy_extract: energy       # energy extractor type
#energy_normalize: global_mvn # normalizer for the energy feature

##########################################################
#            OPTIMIZER & SCHEDULER SETTING               #
##########################################################
optim: adam            # optimizer type
optim_conf:            # keyword arguments for selected optimizer
    lr: 1            # learning rate
scheduler: noamlr      # scheduler type
scheduler_conf:        # keyword arguments for selected scheduler
    model_size: 1536    # model size, a.k.a., attention dimension
    warmup_steps: 4000 # the number of warmup steps

##########################################################
#                OTHER TRAINING SETTING                  #
##########################################################
num_iters_per_epoch: 500  # number of iterations per epoch
max_epoch: 1000            # number of epochs
grad_clip: 1.0            # gradient clipping norm
grad_noise: false         # whether to use gradient noise injection
accum_grad: 1             # gradient accumulation
# batch_bins: 1800000      # batch bins (feats_type=raw)
num_prosody_clusters: 5
batch_bins: 17500      # batch bins (feats_type=raw)
batch_type: numel         # how to make batch
sort_in_batch: descending # how to sort data in making batch
sort_batch: descending    # how to sort created batches
num_workers: 1            # number of workers of data loader
train_dtype: float32      # dtype in training
log_interval: null        # log interval in iterations
keep_nbest_models: 5      # number of models to keep
num_att_plot: 3           # number of attention figures to be saved in every check
seed: 0                   # random seed number
best_model_criterion:     # criterion to save the best models
-   - valid
    - loss
    - min
-   - train
    - loss
    - min
